{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04fb049-5b85-45ae-a82b-ae55a2a5280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5f8528-00c4-4cd3-94f6-ec9572a0f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually it represent a LSTM layer\n",
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_dim, self.hidden_dim = input_dim, hidden_dim\n",
    "\n",
    "        # Forget gate parameters\n",
    "        self.W_xf, self.W_hf, self.b_f = self.create_gate_parameters()\n",
    "\n",
    "        # Input gate parameters\n",
    "        self.W_xi, self.W_hi, self.b_i = self.create_gate_parameters()\n",
    "\n",
    "        # Output gate parameters\n",
    "        self.W_xo, self.W_ho, self.b_o = self.create_gate_parameters()\n",
    "\n",
    "        # Candidate cell parameters\n",
    "        self.W_xg, self.W_hg, self.b_g = self.create_gate_parameters()\n",
    "\n",
    "    def create_gate_parameters(self):\n",
    "        W_x = nn.Parameter(torch.zeros(self.input_dim, self.hidden_dim))   # W_x?\n",
    "        W_h = nn.Parameter(torch.zeros(self.hidden_dim, self.hidden_dim))  # W_h?\n",
    "        nn.init.xavier_uniform_(W_x)\n",
    "        nn.init.xavier_uniform_(W_h)\n",
    "        b = nn.Parameter(torch.zeros(self.hidden_dim))\n",
    "        return W_x, W_h, b\n",
    "\n",
    "    def forward(self, x, h_t_1, c_t_1):\n",
    "        # x: [batch_size, seq_len, input_dim]\n",
    "        output_h, output_c = [], []\n",
    "\n",
    "        for i in range(x.shape[1]):\n",
    "            x_t = x[:, i]  # extracts the i-th token for every sequence in the batch (1 token: i-th rows all column)\n",
    "            # or x[:, i, :]\n",
    "\n",
    "            # Forget gate\n",
    "            f_t = torch.sigmoid((x_t @ self.W_xf) + (h_t_1 @ self.W_hf) + self.b_f)\n",
    "\n",
    "            # Input gate\n",
    "            i_t = torch.sigmoid((x_t @ self.W_xi) + (h_t_1 @ self.W_hi) + self.b_i)\n",
    "\n",
    "            # Candidate cell update (g_t or c~_t)\n",
    "            g_t = torch.tanh((x_t @ self.W_xg) + (h_t_1 @ self.W_hg) + self.b_g)\n",
    "\n",
    "            # Cell state update\n",
    "            c_t = (f_t * c_t_1) + (i_t * g_t)\n",
    "\n",
    "            # Output gate\n",
    "            o_t = torch.sigmoid((x_t @ self.W_xo) + (h_t_1 @ self.W_ho) + self.b_o)\n",
    "\n",
    "            # Hidden state update\n",
    "            h_t = torch.tanh(c_t) * o_t\n",
    "\n",
    "            # Store for sequence output\n",
    "            output_h.append(h_t.unsqueeze(1))\n",
    "            output_c.append(c_t.unsqueeze(1))\n",
    "\n",
    "            # Update for next timestep\n",
    "            h_t_1 = h_t\n",
    "            c_t_1 = c_t\n",
    "\n",
    "        return torch.concat(output_h, dim=1), torch.concat(output_c, dim=1) # convert the list into tensor alonge the second dimension (B, 1)\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(MultiLayerLSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # First LSTM layer (input_dim -> hidden_dim)\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(LSTMCell(input_dim, hidden_dim))\n",
    "\n",
    "        # Remaining LSTM layers (hidden_dim -> hidden_dim)\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(LSTMCell(hidden_dim, hidden_dim))\n",
    "\n",
    "        # Dropout between layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Final linear projection back to input dimension\n",
    "        self.proj = nn.Linear(hidden_dim, input_dim)\n",
    "        nn.init.xavier_uniform_(self.proj.weight)\n",
    "        self.proj.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        \"\"\"\n",
    "        x: [batch_size, seq_len, input_dim]\n",
    "        state: (h, c)\n",
    "            # Each layer gets its own independent (h0, c0). each layer has completely separate memory.\n",
    "                h: [num_layers, batch_size, hidden_dim]\n",
    "                c: [num_layers, batch_size, hidden_dim]\n",
    "        \"\"\"\n",
    "        h_prev, c_prev = state   # previous hidden & cell states\n",
    "\n",
    "        # ----- Layer 0 -----\n",
    "        h_out, c_out = self.layers[0](x, h_prev[0], c_prev[0])\n",
    "\n",
    "        # Store the final timestep outputs\n",
    "        h_list = [h_out[:, -1].unsqueeze(0)]\n",
    "        c_list = [c_out[:, -1].unsqueeze(0)]\n",
    "\n",
    "        # ----- Remaining layers -----\n",
    "        for layer_idx in range(1, self.num_layers):\n",
    "            # Apply dropout between layers\n",
    "            dropped = self.dropout(h_out)\n",
    "            h_out, c_out = self.layers[layer_idx](dropped,\n",
    "                                                  h_prev[layer_idx],\n",
    "                                                  c_prev[layer_idx])\n",
    "            h_list.append(h_out[:, -1].unsqueeze(0))\n",
    "            c_list.append(c_out[:, -1].unsqueeze(0))\n",
    "\n",
    "        # Output projection\n",
    "        logits = self.proj(self.dropout(h_out))\n",
    "\n",
    "        # New hidden states for next forward pass\n",
    "        h_new = torch.cat(h_list, dim=0)\n",
    "        c_new = torch.cat(c_list, dim=0)\n",
    "\n",
    "        return logits, (h_new, c_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d5826-1292-434c-a70b-3bffb9971b29",
   "metadata": {},
   "source": [
    "# With details explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46123b8f-b599-412e-8d3c-5619d9908f14",
   "metadata": {},
   "source": [
    "\n",
    "### How Inputs Flow Through a Multi-Layer LSTM\n",
    "\n",
    "The **output sequence of layer 0 becomes the input sequence of layer 1.**  \n",
    "**Not the original `x`.**\n",
    "\n",
    "---\n",
    "\n",
    "### Layer-wise Input Flow\n",
    "\n",
    "- **Input to layer 0:** `x` (original data)  \n",
    "- **Input to layer 1:** `h_out` (output of layer 0)  \n",
    "- **Input to layer 2:** `h_out` from layer 1  \n",
    "- **Input to layer 3:** output from layer 2  \n",
    "- ‚Ä¶ and so on.\n",
    "\n",
    "This is standard in all multi-layer LSTMs.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Shape Always Remains the Same\n",
    "\n",
    "Each layer outputs:\n",
    "\n",
    "```\n",
    "\n",
    "h_out: [batch, seq_len, hidden_dim]\n",
    "\n",
    "````\n",
    "\n",
    "So the input to the next layer is always:\n",
    "\n",
    "```python\n",
    "next_input = h_out\n",
    "````\n",
    "\n",
    "```\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45f9afa-b08a-4094-a163-8a5be0677a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually it represent a LSTM layer\n",
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_dim, self.hidden_dim = input_dim, hidden_dim\n",
    "\n",
    "        # Forget gate parameters\n",
    "        self.W_xf, self.W_hf, self.b_f = self.create_gate_parameters()\n",
    "\n",
    "        # Input gate parameters\n",
    "        self.W_xi, self.W_hi, self.b_i = self.create_gate_parameters()\n",
    "\n",
    "        # Output gate parameters\n",
    "        self.W_xo, self.W_ho, self.b_o = self.create_gate_parameters()\n",
    "\n",
    "        # Candidate cell parameters\n",
    "        self.W_xg, self.W_hg, self.b_g = self.create_gate_parameters()\n",
    "\n",
    "    def create_gate_parameters(self):\n",
    "        W_x = nn.Parameter(torch.zeros(self.input_dim, self.hidden_dim))   # (input_dim, hidden_dim)\n",
    "        W_h = nn.Parameter(torch.zeros(self.hidden_dim, self.hidden_dim))  # (hidden_dim, hidden_dim)\n",
    "        nn.init.xavier_uniform_(W_x)\n",
    "        nn.init.xavier_uniform_(W_h)\n",
    "        b = nn.Parameter(torch.zeros(self.hidden_dim))                     # (hidden_dim,)\n",
    "        return W_x, W_h, b\n",
    "\n",
    "    def forward(self, x, h_t_1, c_t_1):\n",
    "        # x: [batch_size, seq_len, input_dim]\n",
    "        # h_t_1: [batch_size, hidden_dim]\n",
    "        # c_t_1: [batch_size, hidden_dim]\n",
    "\n",
    "        output_h, output_c = [], []\n",
    "\n",
    "        for i in range(x.shape[1]):  \n",
    "            x_t = x[:, i, :]                   \n",
    "            # x_t: [batch_size, input_dim]\n",
    "\n",
    "            # ------------------------- Forget gate -------------------------\n",
    "            # x_t @ W_xf ‚Üí [batch, input_dim] @ [input_dim, hidden_dim]\n",
    "            xWf = x_t @ self.W_xf\n",
    "            # xWf: [batch_size, hidden_dim]\n",
    "\n",
    "            # h_t_1 @ W_hf ‚Üí [batch, hidden_dim] @ [hidden_dim, hidden_dim]\n",
    "            hWf = h_t_1 @ self.W_hf\n",
    "            # hWf: [batch_size, hidden_dim]\n",
    "\n",
    "            f_t = torch.sigmoid(xWf + hWf + self.b_f)\n",
    "            # f_t: [batch_size, hidden_dim]\n",
    "\n",
    "            # ------------------------- Input gate --------------------------\n",
    "            i_t = torch.sigmoid(\n",
    "                (x_t @ self.W_xi) +                 # [batch, hidden_dim]\n",
    "                (h_t_1 @ self.W_hi) +               # [batch, hidden_dim]\n",
    "                self.b_i                            # [hidden_dim]\n",
    "            )\n",
    "            # i_t: [batch_size, hidden_dim]\n",
    "\n",
    "            # ---------------------- Candidate update ------------------------\n",
    "            g_t = torch.tanh(\n",
    "                (x_t @ self.W_xg) +                 # [batch, hidden_dim]\n",
    "                (h_t_1 @ self.W_hg) +               # [batch, hidden_dim]\n",
    "                self.b_g                            # [hidden_dim]\n",
    "            )\n",
    "            # g_t: [batch_size, hidden_dim]\n",
    "\n",
    "            # ------------------------ Cell state ----------------------------\n",
    "            c_t = (f_t * c_t_1) + (i_t * g_t)\n",
    "            # c_t: [batch_size, hidden_dim]\n",
    "\n",
    "            # ------------------------- Output gate --------------------------\n",
    "            o_t = torch.sigmoid(\n",
    "                (x_t @ self.W_xo) +                 # [batch, hidden_dim]\n",
    "                (h_t_1 @ self.W_ho) +               # [batch, hidden_dim]\n",
    "                self.b_o                            # [hidden_dim]\n",
    "            )\n",
    "            # o_t: [batch_size, hidden_dim]\n",
    "\n",
    "            # ------------------------ Hidden state --------------------------\n",
    "            h_t = torch.tanh(c_t) * o_t\n",
    "            # h_t: [batch_size, hidden_dim]\n",
    "\n",
    "            # ------------------------- Store outputs ------------------------\n",
    "            output_h.append(h_t.unsqueeze(1))\n",
    "            # h_t.unsqueeze(1): [batch_size, 1, hidden_dim]\n",
    "\n",
    "            output_c.append(c_t.unsqueeze(1))\n",
    "            # c_t.unsqueeze(1): [batch_size, 1, hidden_dim] --> we add this extra dimension to restore the the dimension of x (i.e for the sentences)\n",
    "\n",
    "            # Update for next timestep\n",
    "            h_t_1 = h_t   # [batch_size, hidden_dim]\n",
    "            c_t_1 = c_t   # [batch_size, hidden_dim]\n",
    "\n",
    "        # Concatenate along seq_len dimension\n",
    "        return (\n",
    "            torch.concat(output_h, dim=1),  # [batch_size, seq_len, hidden_dim] --> we concat them to restore the dimension of x\n",
    "            torch.concat(output_c, dim=1)   # [batch_size, seq_len, hidden_dim]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4947fd-9eae-45fe-8d18-7f70665e3083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(MultiLayerLSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # We build the LSTM stack manually.\n",
    "        # Layer 0 takes input_dim ‚Üí hidden_dim.\n",
    "        # All higher layers take hidden_dim ‚Üí hidden_dim.\n",
    "        # ---------------------------------------------------------\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # First layer (input data enters here)\n",
    "        self.layers.append(LSTMCell(input_dim, hidden_dim))\n",
    "\n",
    "        # Remaining layers (receive output from previous layer)\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(LSTMCell(hidden_dim, hidden_dim))\n",
    "\n",
    "        # Dropout between layers (NOT inside time steps)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Final linear projection to bring hidden_dim ‚Üí input_dim\n",
    "        # (like predicting next token embedding)\n",
    "        self.proj = nn.Linear(hidden_dim, input_dim)\n",
    "        nn.init.xavier_uniform_(self.proj.weight)\n",
    "        self.proj.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        \"\"\"\n",
    "        x:\n",
    "            Shape: [batch_size, seq_len, input_dim]\n",
    "            Meaning: entire input sequence for ALL time steps.\n",
    "\n",
    "        state = (h, c)\n",
    "            h: [num_layers, batch_size, hidden_dim]\n",
    "            c: [num_layers, batch_size, hidden_dim]\n",
    "\n",
    "        Intuition:\n",
    "        - You have a stack of LSTM layers.\n",
    "        - Each layer has its OWN separate (h0, c0).\n",
    "        - Each layer processes the whole sequence.\n",
    "        - The output of layer L becomes the input to layer L+1.\n",
    "        \"\"\"\n",
    "\n",
    "        # Unpack previous hidden & cell states for ALL layers\n",
    "        h_prev, c_prev = state\n",
    "\n",
    "\n",
    "        # =========================================================\n",
    "        # -------------------- LAYER 0 -----------------------------\n",
    "        # This layer receives the original input sequence x.\n",
    "        # We pass x and the initial states for layer 0.\n",
    "        # h_out, c_out shapes = [batch, seq_len, hidden_dim]\n",
    "        # =========================================================\n",
    "        h_out, c_out = self.layers[0](x, h_prev[0], c_prev[0])\n",
    "\n",
    "        # We collect ONLY the final hidden & cell states (from last timestep)\n",
    "        # because next forward() call needs these to continue sequence.\n",
    "        h_list = [h_out[:, -1].unsqueeze(0)]  # shape: [1, batch, hidden_dim]\n",
    "        c_list = [c_out[:, -1].unsqueeze(0)]  # shape: [1, batch, hidden_dim]\n",
    "\n",
    "\n",
    "        # =========================================================\n",
    "        # --------------- REMAINING LAYERS -------------------------\n",
    "        # Each layer receives:\n",
    "        #   - The entire output sequence from previous layer\n",
    "        #   - Its own (h0, c0)\n",
    "        #\n",
    "        # Why dropout here?\n",
    "        #   - Dropout is applied BETWEEN layers,\n",
    "        #   - NOT between timesteps (would break time-dependency).\n",
    "        # =========================================================\n",
    "        for layer_idx in range(1, self.num_layers):\n",
    "\n",
    "            # Dropout prevents layers from depending too heavily\n",
    "            # on the exact output of the previous layer.\n",
    "            dropped = self.dropout(h_out)\n",
    "\n",
    "            # Feed dropped sequence into next layer with its own states\n",
    "            h_out, c_out = self.layers[layer_idx](\n",
    "                dropped,\n",
    "                h_prev[layer_idx],   # each layer has its OWN memory\n",
    "                c_prev[layer_idx]\n",
    "            )\n",
    "\n",
    "            # Collect last timestep state of this layer\n",
    "            h_list.append(h_out[:, -1].unsqueeze(0))\n",
    "            c_list.append(c_out[:, -1].unsqueeze(0))\n",
    "\n",
    "\n",
    "        # =========================================================\n",
    "        # -------- FINAL OUTPUT PROJECTION (hidden ‚Üí input) -------\n",
    "        # Applied only on the final layer output.\n",
    "        #\n",
    "        # h_out shape: [batch, seq_len, hidden_dim]\n",
    "        # After projection:\n",
    "        # logits shape: [batch, seq_len, input_dim]\n",
    "        # =========================================================\n",
    "        logits = self.proj(self.dropout(h_out))\n",
    "\n",
    "\n",
    "        # =========================================================\n",
    "        # -------- RETURN UPDATED STATES FOR NEXT CALL -------------\n",
    "        # h_new, c_new:\n",
    "        #     [num_layers, batch, hidden_dim]\n",
    "        #\n",
    "        # These are the \"final\" states of each layer‚Äôs last timestep.\n",
    "        # Perfect for continuing sequence or training.\n",
    "        # =========================================================\n",
    "        h_new = torch.cat(h_list, dim=0)\n",
    "        c_new = torch.cat(c_list, dim=0)\n",
    "\n",
    "        return logits, (h_new, c_new)\n",
    "        # It is ‚Äúone-to-one‚Äù calling for logits (output length = input length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4889913f-831e-425c-b688-ab9658d0f2f4",
   "metadata": {},
   "source": [
    "**These `h_new` and `c_new` are *not* per-timestep outputs.**  \n",
    "They summarize each layer at the **last timestep** of the sequence.\n",
    "\n",
    "\n",
    "They are returned so that:\n",
    "\n",
    "- you can continue the sequence later,  \n",
    "- keep the states between batches, or  \n",
    "- use them for autoregressive decoding.\n",
    "\n",
    "But they do \\textbf{not} change the fact that your \\texttt{logits} are length-\\(T\\) sequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4009d1-fada-43df-b5fe-89d6b434b3f9",
   "metadata": {},
   "source": [
    "# Understanding `h_new` and `c_new` in a Multi-Layer LSTM\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úî What `h_new` and `c_new` Actually Mean  \n",
    "\n",
    "You have a **multi-layer LSTM**, so each layer has its **own hidden state (h)** and **cell state (c)**.\n",
    "\n",
    "Each layer produces its final states at the **last timestep**:\n",
    "\n",
    "- **Layer 0:** `h0_final`, `c0_final`  \n",
    "- **Layer 1:** `h1_final`, `c1_final`  \n",
    "- **Layer 2:** `h2_final`, `c2_final`  \n",
    "- ‚Ä¶  \n",
    "- **Layer L‚àí1:** `hL‚àí1_final`, `cL‚àí1_final`\n",
    "\n",
    "These represent the LSTM‚Äôs memory **after finishing the entire sequence**.\n",
    "\n",
    "## ‚úî Summary (Very Short)\n",
    "\n",
    "`h_new` and `c_new` =  \n",
    "**‚ÄúThe final hidden and cell states (last timestep) of EVERY layer, stacked into a single tensor.‚Äù**\n",
    "\n",
    "These become the starting states for next forward call for next batch of data:\n",
    "\n",
    "```python\n",
    "forward(x_next, (h_new, c_new))\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úî Visual Intuition  \n",
    "\n",
    "Imagine you have **3 layers** (`L=3`):\n",
    "\n",
    "Final states at the **last timestep**:\n",
    "\n",
    "```\n",
    "\n",
    "Layer 0: h0 ‚Üí shape [B, H]\n",
    "Layer 1: h1 ‚Üí shape [B, H]\n",
    "Layer 2: h2 ‚Üí shape [B, H]\n",
    "\n",
    "```\n",
    "\n",
    "After applying `unsqueeze(0)`:\n",
    "\n",
    "```\n",
    "\n",
    "Layer 0: [1, B, H]\n",
    "Layer 1: [1, B, H]\n",
    "Layer 2: [1, B, H]\n",
    "\n",
    "```\n",
    "\n",
    "After stacking with `torch.cat(..., dim=0)`:\n",
    "\n",
    "```\n",
    "\n",
    "h_new =\n",
    "[\n",
    "[layer0_state]\n",
    "[layer1_state]\n",
    "[layer2_state]\n",
    "]\n",
    "\n",
    "Result shape = [3, B, H]\n",
    "\n",
    "````\n",
    "\n",
    "So `h_new` and `c_new` are simply:\n",
    "\n",
    "> All final states of all layers stacked into one tensor.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úî Why Only the Last Timestep?\n",
    "\n",
    "Because LSTM \"memory\" is defined as:\n",
    "\n",
    "- the hidden state at the **final timestep**, and  \n",
    "- the cell state at the **final timestep**\n",
    "\n",
    "We only carry:\n",
    "\n",
    "- **last `h_t`**\n",
    "- **last `c_t`**\n",
    "\n",
    "for each layer.\n",
    "\n",
    "These final states are needed for:\n",
    "\n",
    "- continuation into next batch chunks  \n",
    "- autoregressive generation  \n",
    "- teacher forcing  \n",
    "- inference continuation  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Understanding ‚ÄúNext Forward Call‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úî Meaning of ‚Äúnext forward() call‚Äù\n",
    "\n",
    "The **next time the model runs its forward function**, NOT a new epoch.\n",
    "\n",
    "There are three common cases:\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úî Case 1 ‚Äî Next Batch in the Same Epoch\n",
    "\n",
    "```python\n",
    "logits, (h_new, c_new) = model(x_batch, (h_prev, c_prev))\n",
    "```\n",
    "\n",
    "Next batch:\n",
    "\n",
    "```python\n",
    "logits, (h_new, c_new) = model(x_next_batch, (h0, c0))\n",
    "# usually reset to zeros\n",
    "```\n",
    "\n",
    "This is a **new forward call**, but **not a new epoch**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úî Case 2 ‚Äî Sequence Continuation (autoregressive or long sequence)\n",
    "\n",
    "```\n",
    "chunk 1 ‚Üí forward()\n",
    "chunk 2 ‚Üí forward()\n",
    "chunk 3 ‚Üí forward()\n",
    "```\n",
    "\n",
    "We pass states forward:\n",
    "\n",
    "```python\n",
    "logits, (h_new, c_new) = model(chunk1, (h0, c0))\n",
    "logits, (h_new, c_new) = model(chunk2, (h_new, c_new))\n",
    "logits, (h_new, c_new) = model(chunk3, (h_new, c_new))\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "> \"Next forward call\" = **next chunk of the SAME sequence**.\n",
    "\n",
    "Still **not** a new epoch.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úî Case 3 ‚Äî Inference (Text Generation)\n",
    "\n",
    "```\n",
    "Step 1 ‚Üí forward()\n",
    "Step 2 ‚Üí forward()\n",
    "Step 3 ‚Üí forward()\n",
    "```\n",
    "\n",
    "Each generation step is one forward call.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úî Summary (Simple)\n",
    "\n",
    "**‚ÄúNext forward() call‚Äù means:**\n",
    "The next time the LSTM processes data through its `forward()` method.\n",
    "\n",
    "**It does NOT mean ‚Äúnext epoch.‚Äù**\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úî When Is ‚ÄúNext Epoch‚Äù?\n",
    "\n",
    "A new epoch happens only after ALL batches are processed once:\n",
    "\n",
    "```\n",
    "Epoch 1:\n",
    "    forward(batch 1)\n",
    "    forward(batch 2)\n",
    "    ...\n",
    "    forward(batch N)\n",
    "\n",
    "Epoch 2:\n",
    "    forward(batch 1)\n",
    "    forward(batch 2)\n",
    "    ...\n",
    "```\n",
    "\n",
    "Between epochs, models usually **reset hidden states to zero**\n",
    "(Unless training a stateful LSTM).\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f291a82-bcd2-4d5c-a713-42f9282a05ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 2, 4, 4],\n",
       "         [7, 6, 3, 8],\n",
       "         [1, 1, 1, 5]],\n",
       "\n",
       "        [[8, 8, 4, 8],\n",
       "         [3, 6, 0, 4],\n",
       "         [5, 1, 4, 4]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst3 = torch.randint(0, 9, (2,3,4)) # 2 matrix of (3, 4)\n",
    "tst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fe835b-cb55-45a4-8d1c-cc77ff4abfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 6, 3, 8],\n",
       "        [3, 6, 0, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst3[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07347ecf-0e12-4166-9bc8-851a157f9783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59794fec-8b3d-4370-ba5d-5455c0aa3224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4, 1, 7],\n",
       "        [4, 3, 0, 7],\n",
       "        [6, 8, 7, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst2 = torch.randint(0, 9, (3, 4))\n",
    "tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35f09e-9ca2-48f5-9caa-1a3dda3bfcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a72c4-f266-4278-a792-cff6ab349891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
